{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leo\\Anaconda3\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.cuda as cuda\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset and creating the DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "valid_dataset = datasets.MNIST('./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding = 1)\n",
    "        torch.nn.init.xavier_uniform_(self.conv1.weight)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding = 1)\n",
    "        torch.nn.init.xavier_uniform_(self.conv2.weight)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        torch.nn.init.xavier_uniform_(self.conv3.weight)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding = 1)\n",
    "        \n",
    "        self.dense1 = nn.Linear(3136, 500)\n",
    "        self.dense2 = nn.Linear(500, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #1st conv layer\n",
    "        x = self.conv1(x)     #32x28x28 output\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        #2nd conv layer\n",
    "        x = self.conv2(x) #32x28x28 output\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x) #32x14x14 output\n",
    "        \n",
    "        #3rd conv layer\n",
    "        x = self.conv3(x) #64x14x14 output\n",
    "        x = self.relu(x)\n",
    "\n",
    "        #4th conv layer\n",
    "        x = self.conv4(x) #64x14x14 output\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x) #64x7x7 output // 64,992 parameters up to this point\n",
    "        \n",
    "        x = x.view(-1, 3136)\n",
    "        \n",
    "        #1st fully connected layer\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        #2nd fully connected layer\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating objects, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda unavailable\n"
     ]
    }
   ],
   "source": [
    "mnist_net = MNIST_Net()\n",
    "\n",
    "try:\n",
    "    if cuda.is_available:\n",
    "        mnist_net.cuda()\n",
    "except:\n",
    "    print('cuda unavailable')\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(mnist_net.parameters(), lr = 0.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 train_accuracy:  91.705 train_loss:  461.5371407456696\n",
      "Epoch:  1 valid_accuracy:  98.26 valid_loss:  17.495558477938175\n",
      "Epoch:  2 train_accuracy:  98.54666666666667 train_loss:  86.34943240135908\n",
      "Epoch:  2 valid_accuracy:  99.0 valid_loss:  10.293900817632675\n",
      "Epoch:  3 train_accuracy:  99.08833333333334 train_loss:  53.98476525768638\n",
      "Epoch:  3 valid_accuracy:  98.91 valid_loss:  9.849783957004547\n",
      "Epoch:  4 train_accuracy:  99.32666666666667 train_loss:  40.22226344048977\n",
      "Epoch:  4 valid_accuracy:  98.88 valid_loss:  10.245033904910088\n",
      "Epoch:  5 train_accuracy:  99.46666666666667 train_loss:  28.627984367311\n",
      "Epoch:  5 valid_accuracy:  99.3 valid_loss:  7.006854213774204\n",
      "Epoch:  6 train_accuracy:  99.62166666666667 train_loss:  22.11600709706545\n",
      "Epoch:  6 valid_accuracy:  99.21 valid_loss:  7.280959911644459\n",
      "Epoch:  7 train_accuracy:  99.75333333333333 train_loss:  15.469483450055122\n",
      "Epoch:  7 valid_accuracy:  99.07 valid_loss:  8.173068568110466\n",
      "Epoch:  8 train_accuracy:  99.79666666666667 train_loss:  11.488535568118095\n",
      "Epoch:  8 valid_accuracy:  99.21 valid_loss:  7.750154867768288\n",
      "Epoch:  9 train_accuracy:  99.83166666666666 train_loss:  10.175491064786911\n",
      "Epoch:  9 valid_accuracy:  99.0 valid_loss:  10.494813337922096\n",
      "Epoch:  10 train_accuracy:  99.895 train_loss:  6.670606091618538\n",
      "Epoch:  10 valid_accuracy:  99.08 valid_loss:  10.405847311019897\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []\n",
    "\n",
    "valid_loss = []\n",
    "valid_accuracy = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0           #keeps the count of the total loss per epoch\n",
    "    accurate_predictions = 0 #keeps the count of the number of accurate predictions in the current epoch\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, targets = data\n",
    "        \n",
    "        try:\n",
    "            if cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                targets = targets.cuda()\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        outputs = mnist_net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Evaluation of accurate predictions\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        accurate_predictions += (prediction == targets.data).sum().numpy().astype('float64')\n",
    "    \n",
    "    train_loss.append(epoch_loss)\n",
    "    train_accuracy.append(100.0 * accurate_predictions/len(train_loader.dataset))\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    accurate_predictions = 0\n",
    "    \n",
    "    for i, data in enumerate(valid_loader):\n",
    "        inputs, targets = data\n",
    "        \n",
    "        try:\n",
    "            if cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                targets = targets.cuda()\n",
    "        except: \n",
    "            pass\n",
    "        \n",
    "        #evaluation of the loss function\n",
    "        outputs = mnist_net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        #evaluation of accurate predictions\n",
    "        _, prediction = torch.max(outputs,1)\n",
    "        accurate_predictions += (prediction == targets.data).sum().numpy().astype('float64')\n",
    "    \n",
    "    valid_loss.append(epoch_loss)\n",
    "    valid_accuracy.append(100 * accurate_predictions/len(valid_loader.dataset))\n",
    "    \n",
    "    print('Epoch: ', epoch+1, 'train_accuracy: ', train_accuracy[-1], 'train_loss: ', train_loss[-1])\n",
    "    print('Epoch: ', epoch+1, 'valid_accuracy: ', valid_accuracy[-1], 'valid_loss: ', valid_loss[-1])\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
