{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import torch\nimport torch.nn as nn\nimport torch.cuda as cuda\nimport torchvision.transforms as transforms\nimport torchvision\nimport matplotlib.pyplot as plt",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "119ca39fd31c771baaad11bb9ff4700b5be9d18e"
      },
      "cell_type": "markdown",
      "source": "## Loading the training data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "66701935e11df1d3ef5f1c954921539e3a473b47"
      },
      "cell_type": "code",
      "source": "training_dataset = torchvision.datasets.ImageFolder('../input/ift6135h19/trainset/trainset', transform = transforms.ToTensor())\ntrain_data, valid_data = torch.utils.data.random_split(training_dataset, (18000, 1998))\ntrain_loader = torch.utils.data.DataLoader(train_data, shuffle = True, batch_size = 16)\nvalid_loader = torch.utils.data.DataLoader(valid_data, shuffle = True, batch_size = 16)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fb169c16906f782570decf43d65ba79fefe26c02"
      },
      "cell_type": "markdown",
      "source": "## CNN Architecture\nInspired by https://towardsdatascience.com/image-classifier-cats-vs-dogs-with-convolutional-neural-networks-cnns-and-google-colabs-4e9af21ae7a8"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a14f0273574f2440a01887b66a7966b2e611325f"
      },
      "cell_type": "code",
      "source": "class CatsVsDogsNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(2)\n        \n        self.conv1 = nn.Conv2d(3, 32, 3, padding = 1)\n        torch.nn.init.xavier_uniform_(self.conv1.weight)\n        self.conv2 = nn.Conv2d(32, 32, 3, padding = 1)\n        torch.nn.init.xavier_uniform_(self.conv2.weight)\n        self.conv3 = nn.Conv2d(32, 64, 3, padding = 1)\n        torch.nn.init.xavier_uniform_(self.conv3.weight)\n        self.conv4 = nn.Conv2d(64, 64, 3, padding = 1)\n        torch.nn.init.xavier_uniform_(self.conv4.weight)\n        self.conv5 = nn.Conv2d(64, 128, 3, padding = 1)\n        torch.nn.init.xavier_uniform_(self.conv5.weight)\n        self.conv6 = nn.Conv2d(128, 128, 3, padding = 1)\n        torch.nn.init.xavier_uniform_(self.conv6.weight)\n        \n        self.dense1 = nn.Linear(8192, 1000)\n        self.dense2 = nn.Linear(1000, 2)\n    \n    def forward(self, x):\n        #1st conv layer\n        x = self.conv1(x)\n        x = self.relu(x)\n        \n        #2nd conv layer\n        x = self.conv2(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        \n        #3rd conv layer\n        x = self.conv3(x)\n        x = self.relu(x)\n\n        #4th conv layer\n        x = self.conv4(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        \n        #5th conv layer\n        x = self.conv5(x)\n        x = self.relu(x)\n        \n        #6th conv layer\n        x = self.conv6(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        \n        x = x.view(-1, 8192)\n        \n        #1st fully connected layer\n        x = self.dense1(x)\n        x = self.relu(x)\n        \n        #2nd fully connected layer\n        x = self.dense2(x)\n        \n        return x\n        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0014a91cea5cbf757eea2e2759b185a03e37c5f3"
      },
      "cell_type": "markdown",
      "source": "## Creating objects, loss function & optimizer"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "679499a5dd1317919f8fc4705b5cfde68a5dfca6"
      },
      "cell_type": "code",
      "source": "cats_dogs_net = CatsVsDogsNet()\n\nif cuda.is_available:\n    cats_dogs_net.cuda()\n    \ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(cats_dogs_net.parameters(), lr = 0.08)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer,4,gamma=0.8)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0195c0c2345736c8180a915fd0f55832057d5a06"
      },
      "cell_type": "markdown",
      "source": "## Training phase"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fa5264ce002106fbfe465a5b74864f20997d8bae"
      },
      "cell_type": "code",
      "source": "train_loss = []\ntrain_accuracy = []\n\nvalid_loss = []\nvalid_accuracy = []\n\nfor epoch in range(10):\n    epoch_loss = 0           #keeps the count of the total loss per epoch\n    accurate_predictions = 0 #keeps the count of the number of accurate predictions in the current epoch\n    scheduler.step()\n    \n    for i, data in enumerate(train_loader):\n        inputs, targets = data\n        \n        if cuda.is_available():\n            inputs = inputs.cuda()\n            targets = targets.cuda()\n            \n        optimizer.zero_grad()\n        outputs = cats_dogs_net(inputs)\n        loss = criterion(outputs, targets)\n        epoch_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n        \n        #Evaluation of accurate predictions\n        _, prediction = torch.max(outputs.data, 1)\n        accurate_predictions += (prediction == targets.data).sum().cpu().numpy().astype('float64')\n    \n    train_loss.append(epoch_loss)\n    train_accuracy.append(100 * accurate_predictions/len(train_loader.dataset))\n    \n    epoch_loss = 0\n    accurate_predictions = 0\n    \n    for i, data in enumerate(valid_loader):\n        inputs, targets = data\n        \n        if cuda.is_available():\n            inputs = inputs.cuda()\n            targets = targets.cuda()\n        \n        #evaluation of the loss function\n        outputs = cats_dogs_net(inputs)\n        loss = criterion(outputs, targets)\n        epoch_loss += loss.item()\n        \n        #evaluation of accurate predictions\n        _, prediction = torch.max(outputs,1)\n        accurate_predictions += (prediction == targets.data).sum().cpu().numpy().astype('float64')\n    \n    valid_loss.append(epoch_loss)\n    valid_accuracy.append(100 * accurate_predictions/len(valid_loader.dataset))\n    \n    print('Epoch: ', epoch+1, 'train_accuracy: ', train_accuracy[-1], 'train_loss: ', train_loss[-1])\n    print('Epoch: ', epoch+1, 'valid_accuracy: ', valid_accuracy[-1], 'valid_loss: ', valid_loss[-1])\n        \n        \n        \n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "24d8eef7d9ba7d1e7ae4511f990d303f158372a1"
      },
      "cell_type": "markdown",
      "source": "## Loading test data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "742f151864dbbb3cd082e84e837a31efab6ac585"
      },
      "cell_type": "code",
      "source": "test_dataset = torchvision.datasets.ImageFolder('../input/testset-numerical-order/testset/testset', transform = transforms.ToTensor())\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0783b52211765fe2e2fd1204849c2f0463f99022"
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport kaggle",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "895940e5c4511237f9bc9c106ec9bd3fca5a0379"
      },
      "cell_type": "markdown",
      "source": "## Classifying the test set"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ec30c6c349c94d630e7bda408d7a6e71fa483d66"
      },
      "cell_type": "code",
      "source": "id_row = np.arange(4999) + 1 \nprediction_list = []\nfor i, data in enumerate(test_loader):\n    inputs, _ = data\n    \n    if cuda.is_available():\n            inputs = inputs.cuda()\n    \n    outputs = cats_dogs_net(inputs)\n    predictions = torch.max(outputs.data,1)[1]\n    prediction_list.extend(list(predictions.cpu().numpy()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb397a876824cee2b54d615a2a5e803356acc197"
      },
      "cell_type": "code",
      "source": "prediction_strings = ['Cat' if x==0 else 'Dog' for x in prediction_list]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9f7e06a3324b6e5ebc204b561f476844f7aad75b"
      },
      "cell_type": "code",
      "source": "submission = pd.DataFrame(\n    {'id': id_row,\n     'label': prediction_strings,\n    })",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e6bd8f6f516888a0b546ee19661f9d024f6a2372"
      },
      "cell_type": "code",
      "source": "submission.to_csv('submission.csv', index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ccddcf0db5635f029168a38e5d066e426412ded2"
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport numpy as np",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ab7c4c458c5a6f1322625fad3d3aa02cd5a0deb8"
      },
      "cell_type": "code",
      "source": "training_error = 100 - np.asarray(train_accuracy)\nvalidation_error = 100 - np.asarray(valid_accuracy)\n\ntraining_loss = np.asarray(train_loss)/18000\nvalidation_loss = np.asarray(valid_loss)/1998\n\nepochs = np.arange(10)+1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5b63737633af9d5ffffa74b4402e8f6db84e9344"
      },
      "cell_type": "code",
      "source": "plt.plot(epochs,training_error, label = 'Training error')\nplt.plot(epochs, validation_error, label = 'Validation error')\nplt.legend(loc='upper right')\nplt.title('Classification error per epoch; training vs validation')\nplt.xlabel('Epoch')\nplt.ylabel('Error per epoch (%)')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "febbef1c53b20426d45e3bdcd6cb6c615a073cdc"
      },
      "cell_type": "code",
      "source": "plt.plot(epochs,training_loss, label = 'Training loss')\nplt.plot(epochs, validation_loss, label = 'Validation loss')\nplt.legend(loc='upper right')\nplt.title('Loss per epoch; training vs validation')\nplt.xlabel('Epoch')\nplt.ylabel('Average loss per epoch')\n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}